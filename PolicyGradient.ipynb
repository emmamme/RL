{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"APS1080_Ex5_Xu_Chen.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNAvRnM8wcjo7T6fJf3BgPp"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"xUJXZTGxy9RB","executionInfo":{"status":"ok","timestamp":1627557022159,"user_tz":-480,"elapsed":3490,"user":{"displayName":"Emma Chen","photoUrl":"","userId":"16939016720264210209"}}},"source":["import sys\n","import gym\n","import numpy as np\n","from keras.layers import Dense\n","from keras.models import Sequential\n","from keras.optimizers import Adam"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U8ZajDX1zGIC","executionInfo":{"status":"ok","timestamp":1627557024988,"user_tz":-480,"elapsed":739,"user":{"displayName":"Emma Chen","photoUrl":"","userId":"16939016720264210209"}},"outputId":"cd92fe8a-c828-454f-d43c-9e58d1e6c494"},"source":["alpha = 0.001\n","\n","model = Sequential()\n","model.add(Dense(64, input_dim=4, activation='relu'))\n","model.add(Dense(64, activation='relu'))\n","model.add(Dense(2, activation='softmax'))\n","model.summary()\n","model.compile(loss=\"categorical_crossentropy\", optimizer=Adam(lr=alpha))"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense (Dense)                (None, 64)                320       \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 64)                4160      \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 2)                 130       \n","=================================================================\n","Total params: 4,610\n","Trainable params: 4,610\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"-Yi6DrovzkwH","executionInfo":{"status":"ok","timestamp":1627557105916,"user_tz":-480,"elapsed":592,"user":{"displayName":"Emma Chen","photoUrl":"","userId":"16939016720264210209"}}},"source":["def get_action(model, state):\n","    policy = model.predict(state, batch_size=1).flatten()\n","    return np.random.choice(env.action_space.n, 1, p=policy)[0]\n","\n","def discount_rewards(discount, rewards):\n","    discounted_rewards = np.zeros_like(rewards)\n","    count = 0\n","    for t in reversed(range(0, len(rewards))):\n","        count = count * discount + rewards[t]\n","        discounted_rewards[t] = count\n","    return discounted_rewards\n","\n","def reshape_state(state):\n","    return np.reshape(state, [1,env.observation_space.shape[0]])\n","\n","def train_model(state_list, action_list, rewards_list, discount, model):\n","    episode_length = len(state_list)\n","    discounted_rewards = discount_rewards(discount, rewards_list)\n","    update_inputs = np.zeros((episode_length, env.observation_space.shape[0]))\n","    target = np.zeros((episode_length, env.action_space.n))\n","\n","    for i in range(episode_length):\n","        update_inputs[i] = state_list[i]\n","        target[i][action_list[i]] = discounted_rewards[i]\n","\n","    model.fit(update_inputs, target, epochs=1, verbose=0)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gocOrmEkz8dn","executionInfo":{"status":"ok","timestamp":1627558702473,"user_tz":-480,"elapsed":906956,"user":{"displayName":"Emma Chen","photoUrl":"","userId":"16939016720264210209"}},"outputId":"da0c9b7c-a38d-491b-f8bb-7dbabae4e036"},"source":["env = gym.make('CartPole-v0')\n","\n","EPISODES = 2000\n","discount = 0.99\n","\n","for e in range(EPISODES):\n","    state = env.reset()\n","    state = np.reshape(state, [1, env.observation_space.shape[0]])\n","    state_list, action_list, rewards_list = [], [], []\n","    step = 0\n","\n","    while True:\n","        step += 1\n","        action = get_action(model, state)\n","        next_state, reward, done, info = env.step(action)\n","        next_state = reshape_state(next_state)\n","\n","        state_list.append(state)\n","        rewards_list.append(reward)\n","        action_list.append(action)\n","        state = next_state\n","\n","        if done:\n","            train_model(state_list, action_list, rewards_list, discount, model)\n","            if e%100 == 0:\n","              print('Episode step: ', step)\n","            break\n"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Episode step:  9\n","Episode step:  10\n","Episode step:  9\n","Episode step:  9\n","Episode step:  9\n","Episode step:  10\n","Episode step:  8\n","Episode step:  10\n","Episode step:  10\n","Episode step:  8\n","Episode step:  11\n","Episode step:  8\n","Episode step:  9\n","Episode step:  11\n","Episode step:  10\n","Episode step:  10\n","Episode step:  8\n","Episode step:  9\n","Episode step:  9\n","Episode step:  9\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CyUxbN5I0KaR","executionInfo":{"status":"ok","timestamp":1627557750039,"user_tz":-480,"elapsed":529,"user":{"displayName":"Emma Chen","photoUrl":"","userId":"16939016720264210209"}}},"source":["def test_policy(model):\n","    avg_steps = []\n","    for iter in range(10):\n","      obs = env.reset()\n","      for i in range(50000):\n","        action = np.argmax(model.predict(reshape_state(obs))[0])\n","        obs, reward, done, info = env.step(action)\n","        if done:\n","          avg_steps.append(i+1)\n","          # print(\"Iterations that were run:\", i+1)\n","          break\n","    avg = sum(avg_steps)/len(avg_steps)\n","    print(\"Average steps for policy:\", avg)\n","    return avg"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ti-VBaIe0Nu2","executionInfo":{"status":"ok","timestamp":1627542835236,"user_tz":-480,"elapsed":441,"user":{"displayName":"Emma Chen","photoUrl":"","userId":"16939016720264210209"}},"outputId":"0c7a47c6-7ab7-49e0-cdbe-21465eb8f6bf"},"source":["test_policy(model)"],"execution_count":28,"outputs":[{"output_type":"stream","text":["Average steps for policy: 9.0\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["9.0"]},"metadata":{"tags":[]},"execution_count":28}]}]}
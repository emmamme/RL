{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ledQiPzXFfe5"
   },
   "source": [
    "### Part A: What is an autonomous machine, and what does autonomy mean?\n",
    "1. > What is an autonomous machine, and what does autonomy mean?\n",
    "\n",
    "  Autonomous machine refers to a subject that is capable of perceiving the environment and make self decisions based on what it learns from the environment. Usually there is a reward system involved in this process to penalize bad actions in order to establish correct cognize of the environment. Autonomy means capability of making decisions independently in an unknown environment or unfamiliar set of rules without external inputs. It could also mean being able to self driven without external force.\n",
    "\n",
    "2.  \n",
    "> a. Classical AI techniques employ trees of decision constructs (if statements, etc.) to achieve some form of \"intelligent\"-like behavior. An example of this is the famous Eliza AI-based \"psychotherapist\". What do you feel are the strengths and weaknesses of such an approach? State and explain three such strengths and three weaknesses.\n",
    "\n",
    "  **Strengths:**\n",
    "  *   Predictable results, given an input to the system, an output can be predicted by going through the if-else statement chain\n",
    "  *   Simple algorithm and easy to understand. Chain of if-else statement is less mathematical which makes it easier to track down each steps.\n",
    "  *   More flexible in terms of corner cases handling. For any corner case, we could simplify add more if-else logic to cover. In this approach, more exceptional cases can be considered which gives us flexibility.\n",
    "\n",
    "  **Weaknesses:** \n",
    "  *    Requires deep understanding of the environment in order to build out an functional system. For example with sequential if else statements, what to do this each steps must be identified upfront and all of logic will remain unchanged during execution.\n",
    "  *   Limited complexity and not tuneable. As mentioned above, once defined, all logic must remain unchanged which makes it impossible to adapt to more complex changing environment.\n",
    "  *   Model is not generalized. Although it might perform well for some scenarios, if-else chain cannot be extended to other tasks or areas.\n",
    "  \n",
    "  > b. Data Science includes signal processing, adaptive filters, supervised and unsupervised machine learning. These techniques solve the modeling problem from the perspective of the data. That is, they serve to classify signals (data), interpolate signals (data), or extract signal from noise. Comment on how these functions relate to artificial intelligence?\n",
    "\n",
    "  Artificial intelligence involves creating algorithms to find patterns or clusters or categories in huge amount of data which aligns with data science techniques. These techinques are essential tools to make AI possible. Based on these techniques, AI can perceive existing data to build a model and utilize it to make perdictions on unseen data which makes it \"smart\". \n",
    "\n",
    "  > c. Control theory concerns the development of feedback laws (i.e., control laws) that strive to push a system (the \"plant\") to a desired state. It does this based on observation of essential characteristics of the plant (the state, or some possibly noisy or lossy observation of the state), and construction of an appropriate feedback signal. How does this tool compare with the prior two, relating to the development of an autonomous system? Explain the similarities and differences from a structural (high level) point of view.\n",
    "\n",
    "  Control theory focuses on finding equilibrium of an unseen environment based on feedbacks from it. This overlaps with AI in certain areas such as reinforcement learning. As a difference, AI also includes data training based methodologies such as supervised and unsupervised learning. In this case, instead of adapting to environment based on system state and feedback dynamically like control theory and reinforcement learning do, these models are often pre-built and trained on sufficient amount of data and stays unchanged when facing unseen dataset. \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o_Z-F4dBd8kH"
   },
   "source": [
    "### Part B: Tic Tac Toe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 233,
     "status": "ok",
     "timestamp": 1621466223975,
     "user": {
      "displayName": "Emma Chen",
      "photoUrl": "",
      "userId": "16939016720264210209"
     },
     "user_tz": 240
    },
    "id": "GwUz3Qf2u44R"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NwipHeHj7jBz"
   },
   "source": [
    "Creating a Board class, it contains some class methods to interact with tic tac toe board as shown below:\n",
    "\n",
    "Players will be assigned to be 1 or -1 automatically, first player will be 1.\n",
    "\n",
    "**reset():** to reset board to original empty state  \n",
    "**action():** to place on the board  \n",
    "**check_result(state):** to verify if one has won or if game ties given a state  \n",
    "**print_board():** to show state of board visually  \n",
    "**get_state():** to return current state of the board  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 270,
     "status": "ok",
     "timestamp": 1621466959495,
     "user": {
      "displayName": "Emma Chen",
      "photoUrl": "",
      "userId": "16939016720264210209"
     },
     "user_tz": 240
    },
    "id": "r8f2WkR9Fh_G"
   },
   "outputs": [],
   "source": [
    "class Board():\n",
    "\n",
    "    board_arr = np.zeros((3,3))\n",
    "    player = 1\n",
    "    \n",
    "    def reset(self):\n",
    "      # reset board to original empty state\n",
    "      self.board_arr = np.zeros((3,3))\n",
    "      self.player = 1\n",
    "\n",
    "    def action(self, x, y):\n",
    "      # to place on the board\n",
    "      # also check if action results in an end game\n",
    "      if (self.board_arr[x, y] != 0):\n",
    "        print(\"Illegal move, please try again!\")\n",
    "        return\n",
    "\n",
    "      self.board_arr[x, y] = self.player\n",
    "      self.print_board()\n",
    "      if self.check_result(self.board_arr) == self.player:\n",
    "        print(\"Congratulations {0} win!\".format(self.player))\n",
    "        return\n",
    "      elif self.check_result(self.board_arr) == 0:\n",
    "        print(\"Hey we tie!\")\n",
    "        return\n",
    "\n",
    "      self.player = self.player * -1\n",
    "      return\n",
    "\n",
    "    def check_result(self, arr):\n",
    "      # verify if one has won or if game ties given a state\n",
    "      # Check horizontal\n",
    "      h = arr.sum(axis=0)\n",
    "      # Check vertical\n",
    "      v = arr.sum(axis=1)\n",
    "      # Check diagonal\n",
    "      d_1 = np.fliplr(arr).diagonal().sum()\n",
    "      d_2 = np.diagonal(arr).sum()\n",
    "\n",
    "      if 3 in h or 3 in v or 3 == d_1 or 3 == d_2:\n",
    "        return 1\n",
    "      elif -3 in h or -3 in v or -3 == d_1 or -3 == d_2:\n",
    "        return -1\n",
    "      elif 0 not in arr:\n",
    "        return 0\n",
    "      return 100\n",
    "\n",
    "    def print_board(self):\n",
    "      # show state of board visually\n",
    "      print(self.board_arr)\n",
    "\n",
    "    def get_state(self):\n",
    "      # get current state of the board, used by minimax algor\n",
    "      return self.board_arr\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b9JJJMiM9Dbj"
   },
   "source": [
    "I tried to play human to human tic tac toe to test this board class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 287,
     "status": "ok",
     "timestamp": 1621466961342,
     "user": {
      "displayName": "Emma Chen",
      "photoUrl": "",
      "userId": "16939016720264210209"
     },
     "user_tz": 240
    },
    "id": "CmkYKy8Cu8Ez",
    "outputId": "827d6240-5ca9-45eb-8e2e-c5e482654823"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "[[ 1. -1.  0.]\n",
      " [ 0.  0.  0.]\n",
      " [ 0.  0.  0.]]\n",
      "[[ 1. -1.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 0.  0.  0.]]\n",
      "[[ 1. -1. -1.]\n",
      " [ 1.  0.  0.]\n",
      " [ 0.  0.  0.]]\n",
      "[[ 1. -1. -1.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]]\n",
      "Congratulations 1 win!\n"
     ]
    }
   ],
   "source": [
    "board = Board()\n",
    "board.reset()\n",
    "board.action(0,0)\n",
    "board.action(0,1)\n",
    "board.action(1,0)\n",
    "board.action(0,2)\n",
    "board.action(2,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zlzn9dRZ-FJU"
   },
   "source": [
    "In this section, I implemented a Player class using minimax algorithm as playing strategy given a tic tac toe board state. This algorithm will perform exhaustive search on all possible moves from given state, calculate the score/rewards of each move and then pick the move with the best score/reward possible.\n",
    "\n",
    "One limitation of this implementation now is it assumes this player to be 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "executionInfo": {
     "elapsed": 231,
     "status": "ok",
     "timestamp": 1621467860369,
     "user": {
      "displayName": "Emma Chen",
      "photoUrl": "",
      "userId": "16939016720264210209"
     },
     "user_tz": 240
    },
    "id": "a68Q-_XRV7Od"
   },
   "outputs": [],
   "source": [
    "class Player():\n",
    "\n",
    "  def __init__(self, player):\n",
    "    self.player = player\n",
    "    return\n",
    "\n",
    "  def get_move(self, board):\n",
    "    # Compute best next move\n",
    "    state = board.get_state()\n",
    "    bestScore = -math.inf\n",
    "    move = math.inf, math.inf\n",
    "    for i in range(0,3):\n",
    "      for j in range(0,3):\n",
    "        if state[i,j] == 0:\n",
    "          state[i,j] = self.player\n",
    "          score = self.minimax(board, state, 0, False)\n",
    "          state[i,j] = 0\n",
    "          if score > bestScore:\n",
    "            bestScore = score\n",
    "            move = i,j\n",
    "    return move\n",
    "\n",
    "  def minimax(self, board, state, depth, isMaximizing):\n",
    "    # Minimax algor to score each move, and reture the best score\n",
    "    result = board.check_result(state)\n",
    "    if result != 100:\n",
    "      return result \n",
    "    \n",
    "    if isMaximizing:\n",
    "      bestScore = -math.inf\n",
    "      for i in range(0,3):\n",
    "        for j in range(0,3):\n",
    "          if state[i,j] == 0:\n",
    "            state[i,j] = self.player\n",
    "            score = self.minimax(board, state, depth + 1, False)\n",
    "            state[i,j] = 0\n",
    "            bestScore = max(score, bestScore)\n",
    "      return bestScore\n",
    "    else:\n",
    "      bestScore = math.inf\n",
    "      for i in range(0,3):\n",
    "        for j in range(0,3):\n",
    "          if state[i,j] == 0:\n",
    "            state[i,j] = self.player * -1\n",
    "            score = self.minimax(board, state, depth + 1, True)\n",
    "            state[i,j] = 0\n",
    "            bestScore = min(score, bestScore)\n",
    "      return bestScore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rIRh3J9q_RDE"
   },
   "source": [
    "I tested Play class by playing against it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 304,
     "status": "ok",
     "timestamp": 1621467863768,
     "user": {
      "displayName": "Emma Chen",
      "photoUrl": "",
      "userId": "16939016720264210209"
     },
     "user_tz": 240
    },
    "id": "v8dIoVR8qnAv",
    "outputId": "82c33c31-84c3-47bd-d80e-25f255f2232e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "p1 = Player(1)\n",
    "board2 = Board()\n",
    "board2.reset()\n",
    "board2.print_board()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22037,
     "status": "ok",
     "timestamp": 1621467886959,
     "user": {
      "displayName": "Emma Chen",
      "photoUrl": "",
      "userId": "16939016720264210209"
     },
     "user_tz": 240
    },
    "id": "N98vGDa2uk2I",
    "outputId": "a514c66d-aa8b-414e-fdbe-5e01b8b826f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "move = p1.get_move(board2)\n",
    "board2.action(move[0], move[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 226,
     "status": "ok",
     "timestamp": 1621467991187,
     "user": {
      "displayName": "Emma Chen",
      "photoUrl": "",
      "userId": "16939016720264210209"
     },
     "user_tz": 240
    },
    "id": "XgjFSLRYwRfw",
    "outputId": "95167096-5b11-466a-d26d-63a82053fafe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1. -1.  0.]\n",
      " [ 0.  0.  0.]\n",
      " [ 0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "board2.action(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 630,
     "status": "ok",
     "timestamp": 1621467995621,
     "user": {
      "displayName": "Emma Chen",
      "photoUrl": "",
      "userId": "16939016720264210209"
     },
     "user_tz": 240
    },
    "id": "rj06Qz0QwVHh",
    "outputId": "1b7278d4-0e8e-447c-a48f-0ba7f29b2233"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1. -1.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "move = p1.get_move(board2)\n",
    "board2.action(move[0], move[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 254,
     "status": "ok",
     "timestamp": 1621467998426,
     "user": {
      "displayName": "Emma Chen",
      "photoUrl": "",
      "userId": "16939016720264210209"
     },
     "user_tz": 240
    },
    "id": "J81i19RhwYPt",
    "outputId": "afd245fb-4948-4499-90ef-3ecdd071ba6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1. -1.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [-1.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "board2.action(2,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 260,
     "status": "ok",
     "timestamp": 1621468007992,
     "user": {
      "displayName": "Emma Chen",
      "photoUrl": "",
      "userId": "16939016720264210209"
     },
     "user_tz": 240
    },
    "id": "wMBf5oiFwblr",
    "outputId": "6e1582e3-f0eb-4be7-85fb-787ca94148bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1. -1.  0.]\n",
      " [ 1.  1.  0.]\n",
      " [-1.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "move = p1.get_move(board2)\n",
    "board2.action(move[0], move[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 252,
     "status": "ok",
     "timestamp": 1621468035659,
     "user": {
      "displayName": "Emma Chen",
      "photoUrl": "",
      "userId": "16939016720264210209"
     },
     "user_tz": 240
    },
    "id": "DwUxF9ahw0wC",
    "outputId": "90d1f339-6192-4e18-803a-8421596e6093"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1. -1.  0.]\n",
      " [ 1.  1.  0.]\n",
      " [-1.  0. -1.]]\n"
     ]
    }
   ],
   "source": [
    "board2.action(2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 210,
     "status": "ok",
     "timestamp": 1621468042148,
     "user": {
      "displayName": "Emma Chen",
      "photoUrl": "",
      "userId": "16939016720264210209"
     },
     "user_tz": 240
    },
    "id": "bPgmWICuw3La",
    "outputId": "fa6de18f-0b9b-490d-98f1-0dd900cfdf52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1. -1.  0.]\n",
      " [ 1.  1.  1.]\n",
      " [-1.  0. -1.]]\n",
      "Congratulations 1 win!\n"
     ]
    }
   ],
   "source": [
    "move = p1.get_move(board2)\n",
    "board2.action(move[0], move[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QyAk7a3RB3vW"
   },
   "source": [
    "Minimax player seems to make best move every step given a updated board state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cgsz5uc-CMS6"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNrwUDcvwkPOsEthTCHKmL/",
   "name": "Ex0_Xu_Chen.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
